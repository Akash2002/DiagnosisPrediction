{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client(project='diagnosis-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets in diagnosis-prediction:\n",
      "\ttest-2002\n"
     ]
    }
   ],
   "source": [
    "buckets = client.list_buckets()\n",
    "\n",
    "print(\"Buckets in {}:\".format(client.project))\n",
    "for item in buckets:\n",
    "    print(\"\\t\" + item.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket name: test-2002\n",
      "Bucket location: US-CENTRAL1\n",
      "Bucket storage class: STANDARD\n"
     ]
    }
   ],
   "source": [
    "bucket = client.get_bucket('test-2002')\n",
    "\n",
    "print(\"Bucket name: {}\".format(bucket.name))\n",
    "print(\"Bucket location: {}\".format(bucket.location))\n",
    "print(\"Bucket storage class: {}\".format(bucket.storage_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blobs in test-2002:\n",
      "\tAaron697_Brekke496_2fa15bc7-8866-461a-9000-f739e425860a.xml\n"
     ]
    }
   ],
   "source": [
    "blobs = bucket.list_blobs()\n",
    "\n",
    "print(\"Blobs in {}:\".format(bucket.name))\n",
    "for item in blobs:\n",
    "    print(\"\\t\" + item.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: test-2002/Aaron697_Brekke496_2fa15bc7-8866-461a-9000-f739e425860a.xml/1599279523513331\n",
      "Size: 426763 bytes\n",
      "Content type: text/xml\n",
      "Public URL: https://storage.googleapis.com/test-2002/Aaron697_Brekke496_2fa15bc7-8866-461a-9000-f739e425860a.xml\n"
     ]
    }
   ],
   "source": [
    "blob = bucket.get_blob('Aaron697_Brekke496_2fa15bc7-8866-461a-9000-f739e425860a.xml')\n",
    "\n",
    "print(\"Name: {}\".format(blob.id))\n",
    "print(\"Size: {} bytes\".format(blob.size))\n",
    "print(\"Content type: {}\".format(blob.content_type))\n",
    "print(\"Public URL: {}\".format(blob.public_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently basing work off of https://stackoverflow.com/questions/28259301/how-to-convert-an-xml-file-to-nice-pandas-dataframe\n",
    "# Attempt to convert XML data into a DataFrame which is more understandable.\n",
    "def iter_docs(author):\n",
    "    author_attr = author.attrib\n",
    "    for doc in author.iter('document'):\n",
    "        doc_dict = author_attr.copy()\n",
    "        doc_dict.update(doc.attrib)\n",
    "        doc_dict['data'] = doc.text\n",
    "        yield doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Blob: test-2002, Aaron697_Brekke496_2fa15bc7-8866-461a-9000-f739e425860a.xml, 1599279523513331>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobdat = blob.download_as_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xml_data = blobdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-795845d28a83>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-795845d28a83>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    etree = ET.parse(https://storage.googleapis.com/test-2002/Aaron697_Brekke496_2fa15bc7-8866-461a-9000-f739e425860a.xml) #create an ElementTree object\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "etree = ET.parse(https://storage.googleapis.com/test-2002/Aaron697_Brekke496_2fa15bc7-8866-461a-9000-f739e425860a.xml) #create an ElementTree object \n",
    "# Error name too long may be from the fact that it thinks that blobdat is the data \n",
    "doc_df = pd.DataFrame(list(iter_docs(etree.getroot())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
